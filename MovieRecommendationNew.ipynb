{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Spark\\\\spark-3.0.0-bin-hadoop2.7'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing pyspark through findspark\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the required libraries\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import udf,col,when\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing SPark Session\n",
    "spark = SparkSession.builder.appName('MovieRecommender').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading the data containing moview ratings into ratings dataframe\n",
    "ratingsDf = spark.read.csv('ratings.csv', inferSchema=True, header=True)\n",
    "ratingsDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "+------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To use select querries\n",
    "ratingsDf.registerTempTable(\"RatingsTable\")\n",
    "spark.sql(\"SELECT * FROM RatingsTable\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Moading the movies data into the movies dataframe\n",
    "moviesDf = spark.read.csv('movies.csv', inferSchema=True, header=True)\n",
    "moviesDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------+--------------------+\n",
      "|movieId|title                         |genres              |\n",
      "+-------+------------------------------+--------------------+\n",
      "|3379   |On the Beach (1959)           |Drama               |\n",
      "|4429   |Moby Dick (1956)              |Drama               |\n",
      "|33649  |Saving Face (2004)            |Comedy|Drama|Romance|\n",
      "|92494  |Dylan Moran: Monster (2004)   |Comedy|Documentary  |\n",
      "|102217 |Bill Hicks: Revelations (1993)|Comedy              |\n",
      "+-------+------------------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moviesDf.registerTempTable(\"MoviesTable\")\n",
    "spark.sql(\"select * from MoviesTable WHERE movieId IN (33649, 4429, 3379, 102217, 92494)\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- imdbId: integer (nullable = true)\n",
      " |-- tmdbId: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading the data linking the movie ids to the imbdId and tmdbId into links dataframe\n",
    "linksDf = spark.read.csv(\"links.csv\", inferSchema=True, header=True)\n",
    "linksDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+\n",
      "|movieId|imdbId|tmdbId|\n",
      "+-------+------+------+\n",
      "|      1|114709|   862|\n",
      "|      2|113497|  8844|\n",
      "|      3|113228| 15602|\n",
      "|      4|114885| 31357|\n",
      "|      5|113041| 11862|\n",
      "+-------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linksDf.registerTempTable(\"LinksTable\")\n",
    "spark.sql(\"SELECT * FROM LinksTable\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf, validationDF = ratingsDf.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ALS Algorithm:**\n",
    "Here we are using the alternate least square algorithm which is a matrix factorization algorithm. Here in the original ratings matrix, the userID is taken on the Y-axis and the MovieID is taken on the X-axis and the corresponding ratings are populated in the matrix. In the ALS algorithm, a ratings matrix of this dimensions is randomly initialized and broken down into two smaller matrices namely the user matrix and the movie matrix, based on the parameter \"rank\". Further, based on the L2 regularization parameter called \"regParam\", the algorithm alternatively adjusts the values in the user matrix and the movie matrix using gradient descent on each iteration defined by the parameter \"maxIter\" in order to reduce the error between the expected values and the predicted values of the ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a parameter grid to train the model in order to pick the best parameters reducing the RMSE. Lesser the RMSE, better the model. \n",
    "errors = []\n",
    "err = 0\n",
    "als = ALS(maxIter=10,userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(als.regParam, [0.1, 0.01, 0.18]) \\\n",
    "    .addGrid(als.rank, range(4,10)) \\\n",
    "    .build()\n",
    "        \n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "crossVal = CrossValidator(estimator=als,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=5)\n",
    "\n",
    "cvModel = crossVal.fit(trainDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean Squared Error is 0.8819449456636101\n"
     ]
    }
   ],
   "source": [
    "bestModel = cvModel.bestModel\n",
    "predictions = bestModel.transform(validationDF)\n",
    "filteredPredictions = predictions.filter(col('prediction') != np.nan)\n",
    "rmse = evaluator.evaluate(filteredPredictions)\n",
    "print(\"Root mean Squared Error is\", str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+\n",
      "|userId|movieId|rating| timestamp|prediction|\n",
      "+------+-------+------+----------+----------+\n",
      "|   603|    471|   4.0| 954482443| 3.1469011|\n",
      "|   500|    471|   1.0|1005528017| 3.4345999|\n",
      "|    57|    471|   3.0| 969753604| 3.7028093|\n",
      "|   217|    471|   2.0| 955943727| 3.3162818|\n",
      "|   448|    471|   4.0|1178980875| 3.5546632|\n",
      "|   216|    471|   3.0| 975212641| 2.9665217|\n",
      "|    32|    471|   3.0| 856737165|  4.231817|\n",
      "|   469|    471|   5.0| 965425364| 3.6266844|\n",
      "|   260|    471|   4.5|1109409455|   3.66671|\n",
      "|   492|    833|   4.0| 863976674| 1.5273117|\n",
      "+------+-------+------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filteredPredictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredPredictions.registerTempTable(\"PredictionsTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-----------------------------+----------------------------------------+------+----------+\n",
      "|userID|movieId|rating|title                        |genres                                  |tmdbId|prediction|\n",
      "+------+-------+------+-----------------------------+----------------------------------------+------+----------+\n",
      "|498   |296    |4.0   |Pulp Fiction (1994)          |Comedy|Crime|Drama|Thriller             |680   |4.043855  |\n",
      "|498   |161    |5.0   |Crimson Tide (1995)          |Drama|Thriller|War                      |8963  |4.3655796 |\n",
      "|498   |380    |3.0   |True Lies (1994)             |Action|Adventure|Comedy|Romance|Thriller|36955 |3.9908948 |\n",
      "|498   |434    |3.0   |Cliffhanger (1993)           |Action|Adventure|Thriller               |9350  |3.8969991 |\n",
      "|498   |585    |4.0   |Brady Bunch Movie, The (1995)|Comedy                                  |9066  |3.1676679 |\n",
      "+------+-------+------+-----------------------------+----------------------------------------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generating top 5 recommendation for a user with user ID 498\n",
    "spark.sql(\"SELECT userID, p.movieId, rating, title, genres, tmdbId, prediction FROM ((PredictionsTable p INNER JOIN MoviesTable m on p.movieId == m.movieId) INNER JOIN LinksTable l on p.movieId == l.movieId) WHERE userID = 498\").show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the the user with ID 498 tends to like Action/Thriller movies and the top 5 recommended movies for him/her are Pulp Fiction, Crimson Tide, True Lies, CLiffhanger and THe Brady Bunch Movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------------+\n",
      "|userID|movieID                            |\n",
      "+------+-----------------------------------+\n",
      "|471   |[8477, 6818, 3379, 102217, 92494]  |\n",
      "|463   |[5075, 33649, 84847, 3379, 104875] |\n",
      "|496   |[3379, 25947, 8477, 2070, 26326]   |\n",
      "|148   |[104875, 33649, 67618, 5075, 84273]|\n",
      "|540   |[3379, 136469, 59018, 33649, 32892]|\n",
      "|392   |[59018, 3379, 141718, 32892, 69524]|\n",
      "|243   |[5075, 84847, 72171, 59018, 131724]|\n",
      "|31    |[104875, 33649, 3379, 8477, 92494] |\n",
      "|516   |[51931, 6201, 4495, 25906, 77846]  |\n",
      "|580   |[5075, 32892, 59018, 141718, 1696] |\n",
      "+------+-----------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generating top 5 recommendations for each user.\n",
    "userRecommendations = bestModel.recommendForAllUsers(5)\n",
    "userRecommendations.registerTempTable(\"RecommendationTable\")\n",
    "spark.sql(\"SELECT userID, recommendations.movieID FROM RecommendationTable\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+\n",
      "|movieId|userId|prediction|\n",
      "+-------+------+----------+\n",
      "|   1580|   543|  4.545098|\n",
      "|   2366|   543| 3.5906284|\n",
      "|   3175|   543| 4.3188796|\n",
      "|   1590|   543|  2.389799|\n",
      "+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ratings predictions of a specific movie for specific users\n",
    "movieIDs = [1580, 2366, 1590, 3175]\n",
    "userIDs = [543, 543, 543, 543]\n",
    "newUserPreds = sqlContext.createDataFrame(zip(movieIDs,userIDs), schema=['movieId','userId'])\n",
    "newPredictions = bestModel.transform(newUserPreds)\n",
    "newPredictions.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
